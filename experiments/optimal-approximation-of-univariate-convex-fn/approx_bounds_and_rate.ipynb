{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    },
    "ExecuteTime": {
     "end_time": "2025-02-12T21:09:20.062420Z",
     "start_time": "2025-02-12T21:09:20.047160Z"
    }
   },
   "source": [
    "cd ../.."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PyCharmProject\\nna_24-25_pham\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:09:27.614435Z",
     "start_time": "2025-02-12T21:09:20.143093Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from data.generators import *\n",
    "from utils.trainer import train_model\n",
    "from utils.evaluator import evaluate_model\n",
    "from utils.visualizer import *\n",
    "from utils.maths import *\n",
    "from model.simple_model import ReLU_Network\n",
    "from typing import Callable"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:09:28.008256Z",
     "start_time": "2025-02-12T21:09:28.000308Z"
    }
   },
   "source": [
    "FUNCTION = lambda x: x**2\n",
    "A = 0\n",
    "B = 1"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:09:28.033120Z",
     "start_time": "2025-02-12T21:09:28.018916Z"
    }
   },
   "source": [
    "error = compute_approximation_error(f = FUNCTION, interval=(A,B))\n",
    "error[\"error\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for the error $\\Delta(S^*)$\n",
    "The explanation for the error $\\Delta(S^*)$ being $0.125$ is provided in the `experiments/conditions.ipynb` notebook. Readers are encouraged to refer to the notebook for a detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T21:09:28.055202Z",
     "start_time": "2025-02-12T21:09:28.044953Z"
    }
   },
   "source": [
    "assert error['c'] == (B+A)/2\n",
    "print(\"C is the midpoint of the interval [A, B], as expected.\")\n",
    "\n",
    "assert error['d'] == (error['c'] + A)/2\n",
    "print(\"D is the midpoint between C and A, as expected.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is the midpoint of the interval [A, B], as expected.\n",
      "D is the midpoint between C and A, as expected.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We observe that the optimal approximation occurs at $C$, which is the midpoint of the interval $[A, B]$.\n",
    "This is because the second derivative of the function $f(x) = x^2$ is constant and equal to $2$.\n",
    "\n",
    "Mathematically, this can be expressed as:\n",
    "$$\n",
    "f''(x) = \tconstant\n",
    "$$\n",
    "\n",
    "For a quadratic function, $f(x)$ can be written in terms of its second derivative as:\n",
    "$$\n",
    "f(x) = [0.5 \\cdot f''(x)] \\cdot x^2 + k \\cdot x + e,\n",
    "$$\n",
    "where $k$ and $e$ are constants.\n",
    "\n",
    "The derivative at the midpoint $c$ can be calculated as:\n",
    "$$\n",
    "f'(c) = \\frac{f(b) - f(a)}{b - a}.\n",
    "$$\n",
    "\n",
    "Substituting the values of $f(b)$ and $f(a)$ into the equation:\n",
    "$$\n",
    "f'(c) = \\frac{\\left( \\frac{f'' \\cdot b^2}{2} + k \\cdot b \\right) - \\left( \\frac{f'' \\cdot a^2}{2} + k \\cdot a \\right)}{b - a}.\n",
    "$$\n",
    "\n",
    "Simplifying further:\n",
    "$$\n",
    "f'(c) = \\frac{f'' \\cdot (b-a) \\cdot (b+a)}{2(b-a)} + k.\n",
    "$$\n",
    "\n",
    "This reduces to:\n",
    "$$\n",
    "f'(c) = \\frac{f'' \\cdot (b+a)}{2} + k = f'' \\cdot c + k.\n",
    "$$\n",
    "\n",
    "This implies that $c = \\frac{a+b}{2}$ is the optimal approximation for the function $f(x)$ when $f''(x)$ is constant.\n",
    "\n",
    "Similarly, it can be shown that $d = \\frac{c+a}{2}$ is the midpoint between $c$ and $a$, providing further approximation points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof of Theorem 2: Bounds on Approximation Error\n",
    "\n",
    "We observe that the optimal approximation error occurs when the function has constant second-order derivatives.\n",
    "Let $\\bar{f}(x)$ represent the upper-bound approximation of the function $f(x)$, where the second derivative\n",
    "of $\\bar{f}(x)$ is constant and equal to $\\max_{x \\in [a,b]} f''(x)$.\n",
    "Similarly, let $\\underline{f}(x)$ represent the lower-bound approximation, where the second derivative is \n",
    "constant and equal to $\\min_{x \\in [a,b]} f''(x)$.\n",
    "\n",
    "### Upper Bound\n",
    "The upper bound of $\\Delta(f_n^*)$ is derived as follows:\n",
    "$$\n",
    "\\Delta(f_n^*) \\leq \\Delta(\\bar{f}_n^*) \\leq \\frac{(b-a)^2}{16 \\cdot n^2} \\cdot \\max_{x \\in [a,b]} f''(x).\n",
    "$$\n",
    "\n",
    "This is because $c_i$, the point of optimal approximation, lies at the midpoint of each segment $[a_i, b_i]$. Mathematically:\n",
    "$$\n",
    "c_i - a_i = \\frac{b_i - a_i}{2}, \\quad d_i - a_i = \\frac{b_i - a_i}{4}.\n",
    "$$\n",
    "\n",
    "Substituting these values:\n",
    "$$\n",
    "\\Delta(S_i^*) \\leq \\frac{b_i - a_i}{4} \\cdot \\bar{f}'' \\cdot \\left[ \\frac{b_i - a_i}{2} - \\frac{b_i - a_i}{4} \\right] = \\frac{(b_i - a_i)^2}{16} \\cdot \\max_{x \\in [a,b]} f''(x).\n",
    "$$\n",
    "\n",
    "Summing across $n$ equal segments ($b_i - a_i = \\frac{b-a}{n}$):\n",
    "$$\n",
    "\\Delta(\\bar{f}_n^*) \\leq \\frac{(b-a)^2}{16 \\cdot n^2} \\cdot \\max_{x \\in [a,b]} f''(x).\n",
    "$$\n",
    "\n",
    "### Lower Bound\n",
    "Similarly, the lower bound is:\n",
    "$$\n",
    "\\Delta(f_n^*) \\geq \\Delta(\\underline{f}_n^*) \\geq \\frac{(b-a)^2}{16 \\cdot n^2} \\cdot \\min_{x \\in [a,b]} f''(x).\n",
    "$$\n",
    "\n",
    "### Final Result\n",
    "Combining both bounds, we conclude:\n",
    "$$\n",
    "\\frac{(b-a)^2}{16 \\cdot n^2} \\cdot \\min_{x \\in [a,b]} f''(x) \\leq \\Delta(f_n^*) \\leq \\frac{(b-a)^2}{16 \\cdot n^2} \\cdot \\max_{x \\in [a,b]} f''(x).\n",
    "$$\n",
    "\n",
    "This completes the proof of Theorem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Rate\n",
    "The convergence rate of the error $\\Delta(f_n^*)$ is $\\mathcal{O}(n^{-2})$. This implies that the error decreases quadratically with the number of segments $n$.\n",
    "\n",
    "Since $b-a$ is irrelevant to the convergence rate while being the interval length, the error is independent of the interval length. Meanwhile, minimal and maximal second derivatives are crucial for the error bounds, also not affecting the convergence rate.\n",
    "\n",
    "Therefore, the error $\\Delta(f_n^*)$ is independent of the interval length and converges quadratically with the number of segments $n$. In other words, the Convergence Rate is $\\mathcal{O}(n^{-2})$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
